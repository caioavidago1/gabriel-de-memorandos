"""
Chat UI Components - Componentes de interface para o chat com IA
"""
import streamlit as st
from typing import Dict, Optional, List
from .chat_handler import ChatHandler
from model_config import AVAILABLE_MODELS, get_model_display_name, get_default_model
from core.ui_messages import show_warning, show_error, show_success


def _handle_chat_message(
    user_query: str,
    field_name: str,
    paragraph_idx: int,
    current_paragraph: str,
    all_section_paragraphs: List[str],
    facts: Dict,
    memo_type: str,
    memo_id: Optional[str],
    chat_history_key: str,
    model: str = "gpt-4o",
    temperature: float = 0.3
):
    """Processa mensagem do chat"""
    with st.spinner(f"ü§ñ Processando com {model}..."):
        try:
            # Inicializar handler com modelo e temperatura selecionados
            chat_handler = ChatHandler(model=model, temperature=temperature)
            
            # Processar mensagem com contexto completo
            result = chat_handler.process_chat_message(
                user_query=user_query,
                current_paragraph=current_paragraph,
                section_name=field_name,
                all_section_paragraphs=all_section_paragraphs,
                current_paragraph_idx=paragraph_idx,
                facts=facts,
                memo_type=memo_type,
                memo_id=memo_id,
                conversation_history=st.session_state[chat_history_key]
            )
            
            if not result["success"]:
                show_error("Erro ao processar", details=result.get("error", ""))
                return
            
            # Adicionar query do usu√°rio ao hist√≥rico
            st.session_state[chat_history_key].append({
                "role": "user",
                "content": user_query
            })
            
            # Processar resultado baseado no tipo
            if result["type"] == "modification":
                # Atualizar par√°grafo existente
                st.session_state.field_paragraphs[field_name][paragraph_idx] = result["content"]
                
                # CR√çTICO: Incrementar vers√£o para for√ßar Streamlit a recriar widget com novo valor
                version_key = f"{field_name}_{paragraph_idx}"
                if "paragraph_versions" not in st.session_state:
                    st.session_state.paragraph_versions = {}
                if version_key not in st.session_state.paragraph_versions:
                    st.session_state.paragraph_versions[version_key] = 0
                st.session_state.paragraph_versions[version_key] += 1
                
                st.session_state[chat_history_key].append({
                    "role": "assistant",
                    "content": result.get("message", "Par√°grafo modificado conforme solicitado.")
                })
                
                show_success("‚úÖ Par√°grafo atualizado!", use_toast=True)
            
            elif result["type"] == "new_paragraph":
                # Adicionar novo par√°grafo ao final da se√ß√£o
                st.session_state.field_paragraphs[field_name].append(result["content"])
                
                st.session_state[chat_history_key].append({
                    "role": "assistant",
                    "content": result.get("message", "Novo par√°grafo criado e adicionado √† se√ß√£o.")
                })
                
                show_success(f"‚úÖ Novo par√°grafo adicionado! (Total: {len(st.session_state.field_paragraphs[field_name])})", use_toast=True)
            
            else:  # question
                # Responder pergunta
                st.session_state[chat_history_key].append({
                    "role": "assistant",
                    "content": result["content"]
                })
            
            st.rerun()
            
        except Exception as e:
            show_error("Erro ao processar", details=str(e))


def _handle_regenerate_paragraph(
    field_name: str,
    paragraph_idx: int,
    current_paragraph: str,
    all_section_paragraphs: List[str],
    facts: Dict,
    memo_type: str,
    memo_id: Optional[str],
    model: str = "gpt-4o",
    temperature: float = 0.3
):
    """Regenera par√°grafo com otimiza√ß√µes"""
    with st.spinner(f"‚ú® Otimizando com {model}..."):
        try:
            chat_handler = ChatHandler(model=model, temperature=temperature)
            
            result = chat_handler.regenerate_paragraph(
                current_paragraph=current_paragraph,
                section_name=field_name,
                all_section_paragraphs=all_section_paragraphs,
                current_paragraph_idx=paragraph_idx,
                facts=facts,
                memo_type=memo_type,
                memo_id=memo_id
            )
            
            if result["success"]:
                st.session_state.field_paragraphs[field_name][paragraph_idx] = result["content"]
                
                # CR√çTICO: Incrementar vers√£o para for√ßar Streamlit a recriar widget com novo valor
                version_key = f"{field_name}_{paragraph_idx}"
                if "paragraph_versions" not in st.session_state:
                    st.session_state.paragraph_versions = {}
                if version_key not in st.session_state.paragraph_versions:
                    st.session_state.paragraph_versions[version_key] = 0
                st.session_state.paragraph_versions[version_key] += 1
                
                show_success("‚úÖ Par√°grafo otimizado!", use_toast=True)
                st.rerun()
            else:
                show_error("Erro ao otimizar par√°grafo", details=result.get("error", ""))
                
        except Exception as e:
            show_error("Erro ao otimizar par√°grafo", details=str(e))


def render_fixed_chat_panel(
    field_name: str,
    paragraph_idx: int,
    current_paragraph: str,
    all_section_paragraphs: List[str],
    facts: Dict,
    memo_type: str,
    memo_id: Optional[str]
):
    """
    Renderiza painel de chat fixo √† direita para edi√ß√£o de par√°grafo
    
    Args:
        field_name: Nome do campo/se√ß√£o
        paragraph_idx: √çndice do par√°grafo focado
        current_paragraph: Conte√∫do atual do par√°grafo
        all_section_paragraphs: Lista com todos os par√°grafos da se√ß√£o
        facts: Fatos extra√≠dos
        memo_type: Tipo de memorando
        memo_id: ID do memo para busca RAG
    """
    # Usar container do Streamlit
    with st.container():

        # Cabe√ßalho do chat 
        st.markdown("### Assistente de IA")
        st.caption(f"**{field_name}** ‚Ä¢ Par√°grafo {paragraph_idx + 1}")
        
        # Configura√ß√µes compactas 
        with st.expander("Configura√ß√µes", expanded=False):
            # Inicializar configura√ß√µes no session_state
            chat_config_key = f"chat_config_{field_name}_{paragraph_idx}"
            if chat_config_key not in st.session_state:
                st.session_state[chat_config_key] = {
                    "model": get_default_model(),
                    "temperature": 0.3
                }
            
            # Seletor de modelo compacto
            model_options = list(AVAILABLE_MODELS.keys())
            selected_model = st.selectbox(
                "Modelo:",
                options=model_options,
                format_func=get_model_display_name,
                index=model_options.index(st.session_state[chat_config_key]["model"]) if st.session_state[chat_config_key]["model"] in model_options else 0,
                key=f"model_select_fixed_{field_name}_{paragraph_idx}",
                help="Escolha o modelo de IA"
            )
            
            # Slider de temperatura compacto
            temperature = st.slider(
                "Criatividade:",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state[chat_config_key]["temperature"],
                step=0.1,
                key=f"temp_select_fixed_{field_name}_{paragraph_idx}",
                help="0.0 = preciso | 1.0 = criativo"
            )
            
            # Atualizar configura√ß√µes
            st.session_state[chat_config_key]["model"] = selected_model
            st.session_state[chat_config_key]["temperature"] = temperature
        
        # Par√°grafo Original (para refer√™ncia)
        with st.expander("Par√°grafo Original", expanded=False):
            # Obter par√°grafo original
            original_para_key = f"original_paragraph_{field_name}_{paragraph_idx}"
            original_paragraph = st.session_state.get(original_para_key, current_paragraph)
            
            # Se ainda n√£o h√° original salvo, salvar o atual como original
            if original_para_key not in st.session_state:
                st.session_state[original_para_key] = current_paragraph
                original_paragraph = current_paragraph
            
            if not original_paragraph.strip():
                st.caption("*Vazio*")
            else:
                st.text_area(
                    "Par√°grafo original (somente leitura)",
                    value=original_paragraph,
                    height=150,
                    key=f"original_display_{field_name}_{paragraph_idx}",
                    disabled=True,
                    label_visibility="collapsed",
                )
        
        # Contexto da se√ß√£o 
        with st.expander(f"Todos os Par√°grafos ({len(all_section_paragraphs)})", expanded=False):
            for idx, para in enumerate(all_section_paragraphs):
                if para.strip():
                    marker = "**" if idx == paragraph_idx else ""
                    end_marker = "**" if idx == paragraph_idx else ""
                    st.caption(f"{marker}P{idx+1}:{end_marker} {para[:60]}...")
        
        # Inicializar hist√≥rico de conversa se n√£o existir
        chat_history_key = f"chat_history_{field_name}_{paragraph_idx}"
        if chat_history_key not in st.session_state:
            st.session_state[chat_history_key] = []
        
        # √Årea de mensagens 
        st.markdown("**Conversa**")
        
        if st.session_state[chat_history_key]:
            # Container com scroll para mensagens (√∫ltimas 8)
            for msg in st.session_state[chat_history_key][-8:]:
                if msg["role"] == "user":
                    with st.chat_message("user"):
                        st.write(msg["content"])
                else:
                    with st.chat_message("assistant"):
                        st.write(msg["content"])
        else:
            st.info("**Exemplos:**\n- Seja mais conciso\n- Crie par√°grafo sobre riscos\n- Qual √© a receita?")
        
        # Input de comando
        user_query = st.text_input(
            "Instru√ß√£o:",
            key=f"chat_input_fixed_{field_name}_{paragraph_idx}",
            placeholder="Ex: seja mais t√©cnico",
            label_visibility="collapsed"
        )
        
        # Bot√µes de a√ß√£o 
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Enviar", key=f"send_{field_name}_{paragraph_idx}", width='stretch', type="primary"):
                if user_query.strip():
                    chat_config = st.session_state.get(chat_config_key, {"model": "gpt-4o", "temperature": 0.3})
                    _handle_chat_message(
                        user_query, field_name, paragraph_idx, current_paragraph,
                        all_section_paragraphs, facts, memo_type, memo_id,
                        chat_history_key, chat_config["model"], chat_config["temperature"]
                    )
                else:
                    show_warning("Digite uma instru√ß√£o")
        
        with col2:
            if st.button("Otimizar", key=f"opt_{field_name}_{paragraph_idx}", width='stretch', help="Melhora o par√°grafo automaticamente"):
                chat_config = st.session_state.get(chat_config_key, {"model": "gpt-4o", "temperature": 0.3})
                _handle_regenerate_paragraph(
                    field_name, paragraph_idx, current_paragraph,
                    all_section_paragraphs, facts, memo_type, memo_id,
                    chat_config["model"], chat_config["temperature"]
                )
        
        # Bot√£o limpar hist√≥rico 
        if st.session_state[chat_history_key]:
            if st.button("Limpar Hist√≥rico", key=f"clear_{field_name}_{paragraph_idx}", width='stretch', help="Limpar hist√≥rico de conversa"):
                st.session_state[chat_history_key] = []
                st.rerun()
