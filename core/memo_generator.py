"""
Gera√ß√£o profissional de memorandos de Private Equity

Baseado em an√°lise de memos reais de fundos de PE/Search Funds brasileiros.
Estilo: anal√≠tico, cr√≠tico, baseado em dados, com foco em valida√ß√£o.

Arquitetura de Agentes Especializados:
- Search Fund ‚Üí orchestrator com 5 agentes especializados
- Gestora ‚Üí orchestrator com 5 agentes especializados
- Outros tipos usam prompts gen√©ricos
"""

import asyncio
from typing import Dict, List, Optional, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import json


# Mapeamento de sections de facts para se√ß√µes de memo
SECTION_MAPPING = {
    "identification": {
        "keywords": ["introdu√ß√£o", "introduction", "overview", "sum√°rio"],
        "title": "1. Introdu√ß√£o"
    },
    "transaction_structure": {
        "keywords": ["transa√ß√£o", "transaction", "estrutura", "valuation", "deal"],
        "title": "2. Estrutura da Transa√ß√£o"
    },
    "financials_history": {
        "keywords": ["financials", "hist√≥rico", "receita", "ebitda", "margem"],
        "title": "3. Hist√≥rico Financeiro"
    },
    "saida": {
        "keywords": ["proje√ß√µes", "sa√≠da", "exit", "crescimento", "forecast"],
        "title": "4. Proje√ß√µes e Sa√≠da"
    },
    "returns": {
        "keywords": ["retornos", "returns", "irr", "moic", "retorno"],
        "title": "5. Retornos"
    },
    "qualitative": {
        "keywords": ["mercado", "market", "empresa", "company", "modelo", "riscos", "qualitativo"],
        "title": "6. Aspectos Qualitativos"
    }
}


def build_pe_system_prompt(section_title: str) -> str:
    """
    Cria system prompt espec√≠fico para analista de Private Equity.
    
    Baseado em an√°lise de memos reais de PE/Search Funds.
    """
    return f"""Voc√™ √© um analista s√™nior de Private Equity/Search Funds escrevendo a se√ß√£o "{section_title}" de um Investment Memo profissional.

**ESTILO E TOM:**
- Tom anal√≠tico, cr√≠tico mas justo, primeira pessoa do plural ("estamos", "precisaremos")
- Postura de ceticismo balanceado: destaque positivos MAS sempre sinalize riscos e incertezas
- Cada afirma√ß√£o deve ser sustentada por n√∫meros espec√≠ficos, percentuais ou m√©tricas
- Use voz ativa e senten√ßas concisas (3-5 linhas por par√°grafo)

**REGRAS OBRIGAT√ìRIAS:**
‚úÖ Sempre quantifique: "cresceu 14% CAGR" n√£o "cresceu bastante"
‚úÖ Sinalize incertezas: "Ser√° crucial validarmos...", "Ainda temos que aprofundar..."
‚úÖ Compare sempre: "vs. CAGR hist√≥rico de X%", "acima dos peers em Y%"
‚úÖ Use **negrito** para: empresa, valuations, m√∫ltiplos, retornos (IRR/MOIC)
‚úÖ Apresente ambos lados: "Por um lado... por outro...", "Apesar de... vale ressaltar que..."

**ESTRUTURA:**
- Par√°grafos fluidos (n√£o bullets, exceto para listas de produtos/riscos)
- Lidere com contexto, depois dados: "A companhia cresceu consistentemente, entregando CAGR de X%..."
- Cause-and-effect: "Esse n√≠vel √© explicado principalmente por..."

**TERMINOLOGIA PE (use naturalmente):**
- Valuation: EV/EBITDA, m√∫ltiplos, equity value, enterprise value
- Financiamento: seller note, seller finance, acquisition debt, estruturado em X% √† vista
- Retornos: IRR, TIR, MOIC, dividendos
- Crescimento: CAGR, YoY, growth, expans√£o org√¢nica
- Efici√™ncia: EBITDA margin, ROIC, NRR (Net Revenue Retention), churn
- Estrat√©gia: cross-sell, upsell, market share, penetra√ß√£o, moat, switching costs

**O QUE EVITAR:**
‚ùå Linguagem de marketing/vendas ("excelente oportunidade", "incr√≠vel potencial")
‚ùå Afirma√ß√µes sem dados ("muito bom", "grande crescimento")
‚ùå Copiar exemplos literalmente - use apenas como refer√™ncia de ESTILO
‚ùå Inventar n√∫meros - use APENAS os facts fornecidos
‚ùå Markdown headers (##, ###) - use par√°grafos fluidos

**OUTPUT:**
- 2-4 par√°grafos bem conectados
- Cada par√°grafo: 3-5 frases
- Separar par√°grafos com linha em branco
- N√ÉO numerar par√°grafos"""


def build_user_prompt(
    section_title: str,
    facts: Dict[str, Any],
    memo_type: str,
    examples: List[str]
) -> str:
    """
    Monta prompt do usu√°rio com facts e exemplos de refer√™ncia.
    """
    # Limpar facts vazios/None
    cleaned_facts = {k: v for k, v in facts.items() if v not in (None, "", [], {})}
    
    prompt_parts = [
        f"**TAREFA:** Escrever a se√ß√£o '{section_title}' para um {memo_type}",
        "",
        "**FACTS EXTRA√çDOS (use APENAS esses dados):**"
    ]
    
    # Formatar facts de forma leg√≠vel
    for key, value in cleaned_facts.items():
        if isinstance(value, (list, dict)):
            prompt_parts.append(f"- {key}: {json.dumps(value, ensure_ascii=False)}")
        else:
            prompt_parts.append(f"- {key}: {value}")
    
    # Adicionar exemplos de refer√™ncia se dispon√≠veis
    if examples:
        prompt_parts.append("")
        prompt_parts.append("**EXEMPLOS DE REFER√äNCIA (para inspirar ESTILO e ESTRUTURA, N√ÉO copie conte√∫do):**")
        prompt_parts.append("")
        
        for i, example in enumerate(examples[:3], 1):
            prompt_parts.append(f"--- Exemplo {i} ---")
            prompt_parts.append(example)
            prompt_parts.append("")
    
    prompt_parts.append("**INSTRU√á√ïES:**")
    prompt_parts.append("Escreva 2-4 par√°grafos profissionais para essa se√ß√£o usando os facts acima.")
    prompt_parts.append("Siga o estilo anal√≠tico dos exemplos, mas adapte o conte√∫do aos facts espec√≠ficos.")
    prompt_parts.append("Retorne APENAS os par√°grafos, sem cabe√ßalhos ou coment√°rios adicionais.")
    
    return "\n".join(prompt_parts)


async def generate_section_async(
    section_title: str,
    facts: Dict[str, Any],
    memo_type: str,
    memo_examples: List[Dict[str, Any]],
    temperature: float = 0.3,
    rag_context: Optional[str] = None
) -> Dict[str, Any]:
    """
    Gera uma se√ß√£o do memorando usando few-shot learning.
    
    VERS√ÉO 2.0: Com roteamento condicional para Search Fund.
    - Se memo_type cont√©m "Search Fund" ‚Üí usa shortmemo.searchfund.generator
    - Outros tipos ‚Üí usa prompts gen√©ricos
    
    Args:
        section_title: T√≠tulo da se√ß√£o (ex: "1. Introdu√ß√£o")
        facts: Dicion√°rio com facts extra√≠dos para essa se√ß√£o
        memo_type: Tipo de memorando (ex: "Short Memo - Co-investimento (Search Fund)")
        memo_examples: Lista de memos similares da biblioteca
        temperature: Criatividade do modelo (0.0-1.0)
        rag_context: Contexto do RAG/documento (opcional)
        
    Returns:
        Dict com paragraphs gerados e metadata
    """
    from dotenv import load_dotenv
    load_dotenv()
    
    # ========== ROTEAMENTO CONDICIONAL ==========
    # Se for Search Fund ‚Üí usar orchestrator com agentes especializados
    if "Search Fund" in memo_type or "search fund" in memo_type.lower():
        try:
            from shortmemo.searchfund.orchestrator import FIXED_STRUCTURE
            
            # Mapear section_title para agente
            section_agent_map = {
                "1. Introdu√ß√£o": "1. Introdu√ß√£o",
                "2. Mercado": "2. Mercado",
                "2. A Empresa": "3. Empresa",
                "3. Empresa": "3. Empresa",
                "4. Financials": "4. Financials",
                "5. Transa√ß√£o": "5. Transa√ß√£o/Oportunidade",
                "5. Transa√ß√£o/Oportunidade": "5. Transa√ß√£o/Oportunidade",
                "6. Pontos a Aprofundar": "6. Pontos a Aprofundar",
            }
            
            orchestrator_section = section_agent_map.get(section_title)
            
            if orchestrator_section and orchestrator_section in FIXED_STRUCTURE:
                agent = FIXED_STRUCTURE[orchestrator_section]
                
                print(f"   üìù [Search Fund] Gerando '{section_title}' com {agent.__class__.__name__}...")
                
                generated_text = agent.generate(
                    facts=facts,
                    rag_context=rag_context
                )
                
                # Dividir em par√°grafos
                paragraphs = [p.strip() for p in generated_text.split('\n\n') if p.strip()]
                
                print(f"   ‚úÖ '{section_title}': {len(paragraphs)} par√°grafo(s) | Agent: {agent.__class__.__name__}")
                
                return {
                    "paragraphs": paragraphs,
                    "metadata": {
                        "section": section_title,
                        "generator": f"shortmemo.searchfund.{agent.__class__.__name__}",
                        "model": "gpt-4o",
                        "temperature": temperature,
                        "has_rag": rag_context is not None
                    }
                }
            else:
                print(f"   ‚ö†Ô∏è  Se√ß√£o '{section_title}' n√£o mapeada para Search Fund orchestrator")
                # Fallback para prompts gen√©ricos
        
        except ImportError as e:
            print(f"   ‚ö†Ô∏è  Erro ao importar orchestrator Search Fund: {e}")
            print(f"   ‚§∑  Usando prompts gen√©ricos como fallback")
            # Fallback para prompts gen√©ricos
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro no orchestrator Search Fund: {e}")
            print(f"   ‚§∑  Usando prompts gen√©ricos como fallback")
    
    # Se for Gestora ‚Üí usar orchestrator com agentes especializados
    elif "Gestora" in memo_type or "gestora" in memo_type.lower():
        try:
            from shortmemo.gestora.orchestrator import FIXED_STRUCTURE
            
            # Mapear section_title para agente
            section_agent_map = {
                "1. Introdu√ß√£o": "1. Introdu√ß√£o",
                "2. Estrat√©gia e Portf√≥lio": "2. Estrat√©gia e Portf√≥lio",
                "3. Track Record": "3. Track Record",
                "4. Oportunidade": "4. Oportunidade",
                "5. Riscos e Considera√ß√µes": "5. Riscos e Considera√ß√µes",
            }
            
            orchestrator_section = section_agent_map.get(section_title)
            
            if orchestrator_section and orchestrator_section in FIXED_STRUCTURE:
                agent = FIXED_STRUCTURE[orchestrator_section]
                
                print(f"   üìù [Gestora] Gerando '{section_title}' com {agent.__class__.__name__}...")
                
                generated_text = agent.generate(
                    facts=facts,
                    rag_context=rag_context
                )
                
                # Dividir em par√°grafos
                paragraphs = [p.strip() for p in generated_text.split('\n\n') if p.strip()]
                
                print(f"   ‚úÖ '{section_title}': {len(paragraphs)} par√°grafo(s) | Agent: {agent.__class__.__name__}")
                
                return {
                    "paragraphs": paragraphs,
                    "metadata": {
                        "section": section_title,
                        "generator": f"shortmemo.gestora.{agent.__class__.__name__}",
                        "model": "gpt-4o",
                        "temperature": temperature,
                        "has_rag": rag_context is not None
                    }
                }
            else:
                print(f"   ‚ö†Ô∏è  Se√ß√£o '{section_title}' n√£o mapeada para Gestora orchestrator")
                # Fallback para prompts gen√©ricos
        
        except ImportError as e:
            print(f"   ‚ö†Ô∏è  Erro ao importar orchestrator Gestora: {e}")
            print(f"   ‚§∑  Usando prompts gen√©ricos como fallback")
            # Fallback para prompts gen√©ricos
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro no orchestrator Gestora: {e}")
            print(f"   ‚§∑  Usando prompts gen√©ricos como fallback")
    
    # ========== PROMPTS GEN√âRICOS (outros tipos de memo) ==========
    # Mapear section_title para fact_section
    fact_section = None
    for section, config in SECTION_MAPPING.items():
        if config["title"] == section_title:
            fact_section = section
            break
    
    # Gerar sem exemplos (few-shot removido)
    example_paragraphs = []
    
    # Criar LLM
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=temperature
    )
    
    # Montar prompts
    system_prompt = build_pe_system_prompt(section_title)
    user_prompt = build_user_prompt(section_title, facts, memo_type, example_paragraphs)
    
    # Gerar
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    print(f"   üìù Gerando '{section_title}'...")
    
    response = await llm.ainvoke(messages)
    
    # Parse resposta em par√°grafos
    content = response.content.strip()
    
    # Dividir por dupla quebra de linha
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    
    # Se retornou tudo em um bloco, tentar dividir por quebra simples
    if len(paragraphs) == 1 and len(content) > 500:
        single_break = [p.strip() for p in content.split('\n') if p.strip() and len(p.strip()) > 80]
        if len(single_break) > 1:
            paragraphs = single_break
    
    # Limpar numera√ß√£o indesejada (ex: "1. ", "- ")
    import re
    cleaned_paragraphs = []
    for p in paragraphs:
        p_clean = re.sub(r'^\d+\.\s*', '', p)
        p_clean = re.sub(r'^[-‚Ä¢]\s*', '', p_clean)
        cleaned_paragraphs.append(p_clean)
    
    print(f"   ‚úÖ '{section_title}': {len(cleaned_paragraphs)} par√°grafo(s) | {len(example_paragraphs)} exemplo(s) usados")
    
    return {
        "paragraphs": cleaned_paragraphs,
        "metadata": {
            "section": section_title,
            "examples_used": len(example_paragraphs),
            "generator": "generic",
            "model": "gpt-4o",
            "temperature": temperature
        }
    }


def generate_section_sync(
    section_title: str,
    facts: Dict[str, Any],
    memo_type: str,
    temperature: float = 0.3
) -> Dict[str, Any]:
    """
    Wrapper s√≠ncrono para usar no Streamlit.
    
    Args:
        section_title: T√≠tulo da se√ß√£o
        facts: Facts extra√≠dos
        memo_type: Tipo de memorando
        temperature: Criatividade (0.0-1.0, default 0.3 para manter precis√£o)
        
    Returns:
        Dict com paragraphs e metadata
    """
    # Gerar sem exemplos (biblioteca removida)
    memo_examples = []
    
    # Executar async
    return asyncio.run(generate_section_async(
        section_title, facts, memo_type, memo_examples, temperature
    ))


async def regenerate_paragraph_async(
    section_title: str,
    paragraph_index: int,
    current_paragraphs: List[str],
    facts: Dict[str, Any],
    memo_type: str,
    instructions: Optional[str] = None,
    temperature: float = 0.5
) -> str:
    """
    Regenera um par√°grafo espec√≠fico mantendo coer√™ncia com vizinhos.
    
    Args:
        section_title: T√≠tulo da se√ß√£o
        paragraph_index: √çndice do par√°grafo (0-based)
        current_paragraphs: Lista completa de par√°grafos atuais
        facts: Facts da se√ß√£o
        memo_type: Tipo de memorando
        instructions: Instru√ß√µes espec√≠ficas (ex: "Seja mais t√©cnico")
        temperature: Criatividade (0.5 por padr√£o para regenera√ß√£o)
        
    Returns:
        Novo par√°grafo regenerado
    """
    from dotenv import load_dotenv
    load_dotenv()
    
    llm = ChatOpenAI(model="gpt-4o", temperature=temperature)
    
    # Montar contexto com par√°grafos vizinhos
    context_parts = [
        f"**SE√á√ÉO:** {section_title}",
        f"**TIPO:** {memo_type}",
        "",
        "**FACTS:**"
    ]
    
    cleaned_facts = {k: v for k, v in facts.items() if v not in (None, "", [], {})}
    for key, value in cleaned_facts.items():
        context_parts.append(f"- {key}: {value}")
    
    context_parts.append("")
    
    # Par√°grafo anterior (se houver)
    if paragraph_index > 0:
        context_parts.append("**PAR√ÅGRAFO ANTERIOR:**")
        context_parts.append(current_paragraphs[paragraph_index - 1])
        context_parts.append("")
    
    # Par√°grafo atual (a ser regenerado)
    context_parts.append("**PAR√ÅGRAFO ATUAL (REGENERAR):**")
    context_parts.append(current_paragraphs[paragraph_index])
    context_parts.append("")
    
    # Par√°grafo seguinte (se houver)
    if paragraph_index < len(current_paragraphs) - 1:
        context_parts.append("**PAR√ÅGRAFO SEGUINTE:**")
        context_parts.append(current_paragraphs[paragraph_index + 1])
        context_parts.append("")
    
    # Instru√ß√µes espec√≠ficas
    if instructions:
        context_parts.append("**INSTRU√á√ïES ESPEC√çFICAS:**")
        context_parts.append(instructions)
        context_parts.append("")
    
    context_parts.append("**TAREFA:**")
    context_parts.append("Reescreva APENAS o par√°grafo marcado como 'ATUAL', mantendo coer√™ncia com os vizinhos.")
    context_parts.append("Retorne SOMENTE o novo par√°grafo, sem coment√°rios adicionais.")
    
    messages = [
        SystemMessage(content=build_pe_system_prompt(section_title)),
        HumanMessage(content="\n".join(context_parts))
    ]
    
    response = await llm.ainvoke(messages)
    new_paragraph = response.content.strip()
    
    # Limpar numera√ß√£o se houver
    import re
    new_paragraph = re.sub(r'^\d+\.\s*', '', new_paragraph)
    new_paragraph = re.sub(r'^[-‚Ä¢]\s*', '', new_paragraph)
    
    print(f"   üîÑ Par√°grafo {paragraph_index + 1} regenerado")
    
    return new_paragraph


def regenerate_paragraph_sync(
    section_title: str,
    paragraph_index: int,
    current_paragraphs: List[str],
    facts: Dict[str, Any],
    memo_type: str,
    instructions: Optional[str] = None,
    temperature: float = 0.5
) -> str:
    """
    Wrapper s√≠ncrono para regenera√ß√£o de par√°grafo.
    """
    return asyncio.run(regenerate_paragraph_async(
        section_title,
        paragraph_index,
        current_paragraphs,
        facts,
        memo_type,
        instructions,
        temperature
    ))


async def generate_all_sections_async(
    facts: Dict[str, Dict[str, Any]],
    memo_type: str,
    sections_to_generate: Optional[List[str]] = None,
    temperature: float = 0.3
) -> Dict[str, Dict[str, Any]]:
    """
    Gera todas as se√ß√µes do memorando em paralelo.
    
    Args:
        facts: Dict com {section_key: {...facts...}}
        memo_type: Tipo do memorando
        sections_to_generate: Lista de section keys ou None para todas
        temperature: Criatividade do modelo
        
    Returns:
        Dict com {section_title: {paragraphs: [...], metadata: {...}}}
    """
    # Gerar sem exemplos (biblioteca removida)
    memo_examples = []
    
    print(f"\nüöÄ Gerando memorando profissional")
    print(f"   Tipo: {memo_type}")
    
    # Determinar se√ß√µes a gerar
    if sections_to_generate is None:
        sections_to_generate = list(facts.keys())
    
    # Criar tasks de gera√ß√£o
    tasks = []
    section_titles = []
    
    for section_key in sections_to_generate:
        if section_key not in SECTION_MAPPING:
            continue
        
        section_title = SECTION_MAPPING[section_key]["title"]
        section_facts = facts.get(section_key, {})
        
        if not section_facts:
            print(f"   ‚ö†Ô∏è  Se√ß√£o '{section_title}' n√£o tem facts - pulando")
            continue
        
        section_titles.append(section_title)
        tasks.append(generate_section_async(
            section_title, section_facts, memo_type, memo_examples, temperature
        ))
    
    # Executar em paralelo
    print(f"   Gerando {len(tasks)} se√ß√£o(√µes) em paralelo...\n")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Organizar resultados
    generated = {}
    success_count = 0
    
    for section_title, result in zip(section_titles, results):
        if isinstance(result, Exception):
            print(f"   ‚ùå Erro em '{section_title}': {result}")
            generated[section_title] = {
                "paragraphs": [f"Erro ao gerar: {str(result)}"],
                "metadata": {"error": str(result)}
            }
        else:
            generated[section_title] = result
            success_count += 1
    
    print(f"\n‚úÖ Gera√ß√£o conclu√≠da!")
    print(f"   Se√ß√µes geradas com sucesso: {success_count}/{len(tasks)}")
    
    return generated


def generate_all_sections_sync(
    facts: Dict[str, Dict[str, Any]],
    memo_type: str,
    sections_to_generate: Optional[List[str]] = None,
    temperature: float = 0.3
) -> Dict[str, Dict[str, Any]]:
    """
    Wrapper s√≠ncrono para gera√ß√£o completa do memorando.
    """
    return asyncio.run(generate_all_sections_async(
        facts, memo_type, sections_to_generate, temperature
    ))
